{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****Model to Detect Hate Speech****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Loading Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>###</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Type</th>\n",
       "      <th>Target</th>\n",
       "      <th>Implicit</th>\n",
       "      <th>Metaphor/metonymy</th>\n",
       "      <th>Sarcasm/humor</th>\n",
       "      <th>Rhetorical question</th>\n",
       "      <th>Circumlocution</th>\n",
       "      <th>binary-hate-speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>https://www.facebook.com/228735667216_10153273...</td>\n",
       "      <td>Can we shut up about refugees already?</td>\n",
       "      <td>Acceptable speech</td>\n",
       "      <td>No target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acceptable speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.facebook.com/228735667216_10153273...</td>\n",
       "      <td>Why should we? It's the biggest humanitarian c...</td>\n",
       "      <td>Acceptable speech</td>\n",
       "      <td>No target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acceptable speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>https://www.facebook.com/228735667216_10153273...</td>\n",
       "      <td>these refugees adult males are cowards for not...</td>\n",
       "      <td>Background offensive</td>\n",
       "      <td>Migrants</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>https://www.facebook.com/228735667216_10153273...</td>\n",
       "      <td>Does Syria own the BBC?.........</td>\n",
       "      <td>Acceptable speech|Other offensive</td>\n",
       "      <td>No target|Journalist or medium</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>discard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>https://www.facebook.com/228735667216_10153273...</td>\n",
       "      <td>They are all mentally jerking off to the refug...</td>\n",
       "      <td>Background offensive</td>\n",
       "      <td>Migrants</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                                ###  \\\n",
       "0           0  https://www.facebook.com/228735667216_10153273...   \n",
       "1           1  https://www.facebook.com/228735667216_10153273...   \n",
       "2           2  https://www.facebook.com/228735667216_10153273...   \n",
       "3           3  https://www.facebook.com/228735667216_10153273...   \n",
       "4           4  https://www.facebook.com/228735667216_10153273...   \n",
       "\n",
       "                                             Comment  \\\n",
       "0             Can we shut up about refugees already?   \n",
       "1  Why should we? It's the biggest humanitarian c...   \n",
       "2  these refugees adult males are cowards for not...   \n",
       "3                   Does Syria own the BBC?.........   \n",
       "4  They are all mentally jerking off to the refug...   \n",
       "\n",
       "                                Type                          Target  \\\n",
       "0                  Acceptable speech                       No target   \n",
       "1                  Acceptable speech                       No target   \n",
       "2               Background offensive                        Migrants   \n",
       "3  Acceptable speech|Other offensive  No target|Journalist or medium   \n",
       "4               Background offensive                        Migrants   \n",
       "\n",
       "   Implicit  Metaphor/metonymy  Sarcasm/humor  Rhetorical question  \\\n",
       "0       NaN                NaN            NaN                  NaN   \n",
       "1       NaN                NaN            NaN                  NaN   \n",
       "2       0.0                NaN            NaN                  NaN   \n",
       "3       NaN                NaN            NaN                  NaN   \n",
       "4       0.0                NaN            NaN                  NaN   \n",
       "\n",
       "   Circumlocution binary-hate-speech  \n",
       "0             NaN  Acceptable speech  \n",
       "1             NaN  Acceptable speech  \n",
       "2             NaN        Hate speech  \n",
       "3             NaN            discard  \n",
       "4             NaN        Hate speech  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "hatespeechprepared = \"Data/hate-speech-prepared-spreadsheet.csv\"\n",
    "df = pd.read_csv(hatespeechprepared, delimiter=\"\\t\", encoding=\"utf-8\")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Pre-Processing Data*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comment</th>\n",
       "      <th>Target</th>\n",
       "      <th>Implicit</th>\n",
       "      <th>Metaphor/metonymy</th>\n",
       "      <th>Sarcasm/humor</th>\n",
       "      <th>Rhetorical question</th>\n",
       "      <th>Circumlocution</th>\n",
       "      <th>binary-hate-speech</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Can we shut up about refugees already?</td>\n",
       "      <td>No target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acceptable speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Why should we? It's the biggest humanitarian c...</td>\n",
       "      <td>No target</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Acceptable speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>these refugees adult males are cowards for not...</td>\n",
       "      <td>Migrants</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>They are all mentally jerking off to the refug...</td>\n",
       "      <td>Migrants</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hate speech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>You only see what you want to see. Pretty much...</td>\n",
       "      <td>Commenter</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Hate speech</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Comment     Target  Implicit  \\\n",
       "0             Can we shut up about refugees already?  No target       NaN   \n",
       "1  Why should we? It's the biggest humanitarian c...  No target       NaN   \n",
       "2  these refugees adult males are cowards for not...   Migrants       0.0   \n",
       "4  They are all mentally jerking off to the refug...   Migrants       0.0   \n",
       "5  You only see what you want to see. Pretty much...  Commenter       1.0   \n",
       "\n",
       "   Metaphor/metonymy  Sarcasm/humor  Rhetorical question  Circumlocution  \\\n",
       "0                NaN            NaN                  NaN             NaN   \n",
       "1                NaN            NaN                  NaN             NaN   \n",
       "2                NaN            NaN                  NaN             NaN   \n",
       "4                NaN            NaN                  NaN             NaN   \n",
       "5                1.0            1.0                  0.0             0.0   \n",
       "\n",
       "  binary-hate-speech  \n",
       "0  Acceptable speech  \n",
       "1  Acceptable speech  \n",
       "2        Hate speech  \n",
       "4        Hate speech  \n",
       "5        Hate speech  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.drop(columns=['Unnamed: 0', '###', 'Type'])\n",
    "df = df[df['binary-hate-speech'] != 'discard']\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Mapping 'Acceptable speech' to 0 and 'Hate speech' to 1\n",
    "df['binary-hate-speech'] = df['binary-hate-speech'].map({'Acceptable speech': 0, 'Hate speech': 1})\n",
    "\n",
    "# Handling missing text data by imputing with 'unknown' placeholder\n",
    "text_imputer = SimpleImputer(strategy='constant', fill_value='unknown')\n",
    "df['Comment'] = pd.Series(text_imputer.fit_transform(df[['Comment']]).flatten(), index=df.index)\n",
    "\n",
    "# Vectorizing the text data using TF-IDF\n",
    "vectorizer = TfidfVectorizer(max_features=500)\n",
    "text_features = vectorizer.fit_transform(df['Comment'])\n",
    "\n",
    "# Convert the sparse matrix to a DataFrame and merge with the original dataframe\n",
    "text_df = pd.DataFrame(text_features.toarray(), columns=vectorizer.get_feature_names_out(), index=df.index)\n",
    "df = pd.concat([df, text_df], axis=1)\n",
    "\n",
    "# Handling missing values in other columns by filling with the most frequent value (mode)\n",
    "df['Target'] = df['Target'].fillna(df['Target'].mode()[0])\n",
    "\n",
    "# Encoding categorical columns 'Type' and 'Target' as numerical values\n",
    "df['Target'] = df['Target'].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Actual Model*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Invalid classes inferred from unique values of `y`.  Expected: [0], got [nan]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 14\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Training the XGBoost model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m model \u001b[38;5;241m=\u001b[39m xgb\u001b[38;5;241m.\u001b[39mXGBClassifier(use_label_encoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, eval_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlogloss\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Making predictions and evaluating the model\u001b[39;00m\n\u001b[1;32m     17\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/core.py:726\u001b[0m, in \u001b[0;36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    724\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig\u001b[38;5;241m.\u001b[39mparameters, args):\n\u001b[1;32m    725\u001b[0m     kwargs[k] \u001b[38;5;241m=\u001b[39m arg\n\u001b[0;32m--> 726\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/xgboost/sklearn.py:1491\u001b[0m, in \u001b[0;36mXGBClassifier.fit\u001b[0;34m(self, X, y, sample_weight, base_margin, eval_set, verbose, xgb_model, sample_weight_eval_set, base_margin_eval_set, feature_weights)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     expected_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\n\u001b[1;32m   1487\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1488\u001b[0m     classes\u001b[38;5;241m.\u001b[39mshape \u001b[38;5;241m!=\u001b[39m expected_classes\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m   1489\u001b[0m     \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (classes \u001b[38;5;241m==\u001b[39m expected_classes)\u001b[38;5;241m.\u001b[39mall()\n\u001b[1;32m   1490\u001b[0m ):\n\u001b[0;32m-> 1491\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1492\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid classes inferred from unique values of `y`.  \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1493\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexpected_classes\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclasses\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1494\u001b[0m     )\n\u001b[1;32m   1496\u001b[0m params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_xgb_params()\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m callable(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobjective):\n",
      "\u001b[0;31mValueError\u001b[0m: Invalid classes inferred from unique values of `y`.  Expected: [0], got [nan]"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Defining features (X) and target (y)\n",
    "X = df.drop(columns=['binary-hate-speech', 'Comment'])  # Excluding 'Comment' column as it is already vectorized\n",
    "y = df['binary-hate-speech']\n",
    "\n",
    "# Splitting the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Training the XGBoost model\n",
    "model = xgb.XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Making predictions and evaluating the model\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Other Predictors**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
